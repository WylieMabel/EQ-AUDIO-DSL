{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /Users/mabelwylie/Documents/EQ-AUDIO-DSL/.venv/lib/python3.12/site-packages (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/mabelwylie/Documents/EQ-AUDIO-DSL/.venv/lib/python3.12/site-packages (from h5py) (2.3.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in /Users/mabelwylie/Documents/EQ-AUDIO-DSL/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/Users/mabelwylie/Documents/EQ-AUDIO-DSL/raw_data/merge.hdf5\"\n",
    "csv_file = \"/Users/mabelwylie/Documents/EQ-AUDIO-DSL/raw_data/merge.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/dj7vjbyd6kb8q83q6chjb9m00000gn/T/ipykernel_66158/2345539856.py:2: DtypeWarning: Columns (7,11,13,14,24,25,26,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total events in csv file: 1265657\n",
      "total events selected: 1265657\n"
     ]
    }
   ],
   "source": [
    "# reading the csv file into a dataframe:\n",
    "df = pd.read_csv(csv_file)\n",
    "print(f'total events in csv file: {len(df)}')\n",
    "# filterering the dataframe\n",
    "#df = df[(df.trace_category == 'earthquake_local') & (df.source_distance_km <= 20) & (df.source_magnitude > 3)]\n",
    "print(f'total events selected: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['network_code', 'receiver_code', 'receiver_type', 'receiver_latitude',\n",
       "       'receiver_longitude', 'receiver_elevation_m', 'p_arrival_sample',\n",
       "       'p_status', 'p_weight', 'p_travel_sec', 's_arrival_sample', 's_status',\n",
       "       's_weight', 'source_id', 'source_origin_time',\n",
       "       'source_origin_uncertainty_sec', 'source_latitude', 'source_longitude',\n",
       "       'source_error_sec', 'source_gap_deg',\n",
       "       'source_horizontal_uncertainty_km', 'source_depth_km',\n",
       "       'source_depth_uncertainty_km', 'source_magnitude',\n",
       "       'source_magnitude_type', 'source_magnitude_author',\n",
       "       'source_mechanism_strike_dip_rake', 'source_distance_deg',\n",
       "       'source_distance_km', 'back_azimuth_deg', 'snr_db', 'coda_end_sample',\n",
       "       'trace_start_time', 'trace_category', 'trace_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of trace names for the selected data\n",
    "ev_list = df['trace_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back_azimuth_deg \n",
      "coda_end_sample \n",
      "network_code TA\n",
      "p_arrival_sample \n",
      "p_status \n",
      "p_travel_sec \n",
      "p_weight \n",
      "receiver_code 109C\n",
      "receiver_elevation_m 150.0\n",
      "receiver_latitude 32.8889\n",
      "receiver_longitude -117.1051\n",
      "receiver_type HH\n",
      "s_arrival_sample \n",
      "s_status \n",
      "s_weight \n",
      "snr_db \n",
      "source_depth_km \n",
      "source_depth_uncertainty_km \n",
      "source_distance_deg \n",
      "source_distance_km \n",
      "source_error_sec \n",
      "source_gap_deg \n",
      "source_horizontal_uncertainty_km \n",
      "source_id \n",
      "source_latitude \n",
      "source_longitude \n",
      "source_magnitude \n",
      "source_magnitude_author \n",
      "source_magnitude_type \n",
      "source_mechanism_strike_dip_rake \n",
      "source_origin_time \n",
      "source_origin_uncertainty_sec \n",
      "trace_category noise\n",
      "trace_name 109C.TA_201510210555_NO\n",
      "trace_start_time 2015-10-21 05:55:00\n"
     ]
    }
   ],
   "source": [
    "# retrieving selected waveforms from the hdf5 file: \n",
    "dtfl = h5py.File(file_name, 'r')\n",
    "for c, evi in enumerate(ev_list):\n",
    "    dataset = dtfl.get('data/'+str(evi)) \n",
    "    # waveforms, 3 channels: first row: E channel, second row: N channel, third row: Z channel \n",
    "    data = np.array(dataset)\n",
    "\n",
    "    for at in dataset.attrs:\n",
    "        print(at, dataset.attrs[at])    \n",
    "    \n",
    "    break\n",
    "    inp = input(\"Press a key to plot the next waveform!\")\n",
    "    if inp == \"r\":\n",
    "        continue     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1265657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1265657 [00:00<5:51:51, 59.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/Users/mabelwylie/Documents/EQ-AUDIO-DSL/extracted_data/data_E.csv', 'a+') as e, open('/Users/mabelwylie/Documents/EQ-AUDIO-DSL/extracted_data/data_N.csv', 'a+') as n, open('/Users/mabelwylie/Documents/EQ-AUDIO-DSL/extracted_data/data_Z.csv', 'a+') as z:\n",
    "    for i in tqdm(range(len(ev_list))):\n",
    "        evi = ev_list[i]\n",
    "        dataset = dtfl.get('data/'+str(evi)) \n",
    "        data = np.array(dataset)\n",
    "        \n",
    "        # write evi and channel data to files\n",
    "        e.write(f\"{i},{evi},\" + \",\".join(map(str, data[:,0])) + \"\\n\")\n",
    "        n.write(f\"{i},{evi},\" + \",\".join(map(str, data[:,1])) + \"\\n\")\n",
    "        z.write(f\"{i},{evi},\" + \",\".join(map(str, data[:,2])) + \"\\n\")\n",
    "        if i > 5:\n",
    "            break\n",
    "    \n",
    "    # write each line to a separate file\n",
    "e.close()\n",
    "n.close()\n",
    "z.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
